{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PEC 3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mercygeo/AireTesis/blob/master/Regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FhGuhbZ6M5tl"
      },
      "source": [
        "**PEC 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EIdT9iu_Z4Rb"
      },
      "source": [
        "# Regresion: predecir PM25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AHp3M9ZmrIxj"
      },
      "source": [
        "Este notebook obtiene los datos calidad del aire que están disponibles para múltiples estaciones de medición de aire que acumulan niveles de contaminantes cada hora. Conjunto de datos:Datos en tiempo real [Calidad del aire](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=41e01e007c9db410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default) y construye un modelo para predecir el contaminante PM2.5. \n",
        "Para hacer esto, se le va a proveer al modelo con la descripcion de varios contaminantes para un periodo de tiempo. La descripcion incluye contaminantes como: NO2, CO2, NO3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "moB4tpEHxKB3",
        "colab": {}
      },
      "source": [
        "# Use seaborn for pairplot\n",
        "#!pip install seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rRo8oNqZ-Rj",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F_72b0LCNbjx"
      },
      "source": [
        "## El conjunto de datos de calidad del aire\n",
        "\n",
        "El conjunto de datos esta disponible en Portal de datos abiertos del Ayuntamiento de Madrid [Conjunto de datos calidad del aire](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=41e01e007c9db410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default).\n",
        "Se realizo el preprocesamiento de datos el código esta disponible en el repositorio de la tesis en [GitHub](https://github.com/mercygeo/AireTesis)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gFh9ne3FZ-On"
      },
      "source": [
        "### Obtener los datos\n",
        "Se van a cargar los datos pre-procesados de contaminantes del aire desde google sheets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kCVmqKLBsJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "c = gspread.authorize(GoogleCredentials.get_application_default())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nslsRLh7Zss4"
      },
      "source": [
        "\n",
        "2.   Importar el conjunto de datos usando pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3i8QL5HxaYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open our new sheet and read some data.\n",
        "worksheet = c.open('datos_transformados').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "columnas_aire=['FECHA', 'BEN',  'CH4',  'CO',  'EBE','NMHC',  'NO',  'NO2',  'NOx',  'O3', 'PM10',  'PM25',  'SO2',  'TCH',  'TOL']\n",
        "datos_aire_diarios = pd.DataFrame.from_records(rows, columns =columnas_aire)\n",
        "datos_aire_diarios[columnas_aire[1:17]] = datos_aire_diarios[columnas_aire[1:17]].apply(pd.to_numeric) \n",
        "datos_aire_diarios.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0VqVv23LmIwh"
      },
      "source": [
        "Grafico del PM25 por horario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuZEwV1aOXZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.lineplot(x=\"CH4\", y=\"PM25\", data=datos_aire_diarios, color=\"indianred\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axeNvDjtHthQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open our new sheet and read some data.\n",
        "worksheet = c.open('clima_diario_procesado').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "columnas_clima=['FECHA','PRE','TEMP',\t'VEL']\n",
        "datos_clima_diario = pd.DataFrame.from_records(rows, columns =columnas_clima)\n",
        "datos_clima_diario[columnas_clima[1:4]] = datos_clima_diario[columnas_clima[1:4]].apply(pd.to_numeric) \n",
        "datos_clima_diario.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeC-LRY6L9UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.lineplot(x=\"TEMP\", y=\"PRE\", data=datos_clima_diario, color=\"indianred\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cuym4yvk76vU"
      },
      "source": [
        "### Dividir los conjuntos de datos en train y test\n",
        "\n",
        "Se va a dividir el conjunto de datos en training y test. Se va a usar el conjunto de test para la evaluación final del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qn-IGhUE7_1H",
        "colab": {}
      },
      "source": [
        "train_aire_dataset = datos_aire_diarios[columnas_aire[1:17]].sample(frac=0.8,random_state=0)\n",
        "test_aire_dataset = datos_aire_diarios[columnas_aire[1:17]].drop(train_aire_dataset.index)\n",
        "\n",
        "train_clima_dataset = datos_clima_diario[columnas_clima[1:4]].sample(frac=0.8,random_state=0)\n",
        "test_clima_dataset = datos_clima_diario[columnas_clima[1:4]].drop(train_clima_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbkie47HlDoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_aire_dataset.shape)\n",
        "print(train_clima_dataset.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4ubs136WLNp"
      },
      "source": [
        "### Inspeccionar los datos\n",
        "\n",
        "Visualizar la distribución conjunta de algunos pares de columnas del conjunto de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oRKO_x8gWKv-",
        "colab": {}
      },
      "source": [
        "sns.pairplot(train_aire_dataset [['NO2',  'O3', 'PM10',  'PM25']] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ybixyd9tOtpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.pairplot(train_clima_dataset [['TEMP',  'VEL', 'PRE']] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gavKO_6DWRMP"
      },
      "source": [
        "Estadísticas generales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yi2FzC3T21jR",
        "colab": {}
      },
      "source": [
        "train_aire_stats = train_aire_dataset.describe()\n",
        "train_aire_stats.pop(\"PM25\")\n",
        "train_aire_stats = train_aire_stats.transpose()\n",
        "train_aire_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Db7Auq1yXUvh"
      },
      "source": [
        "### Dividir características de las etiquetas\n",
        "\n",
        "Se va a entrenar el modelo para predecir PM25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t2sluJdCW7jN",
        "colab": {}
      },
      "source": [
        "train_aire_labels = train_aire_dataset.pop('PM25')\n",
        "test_aire_labels = test_aire_dataset.pop('PM25')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oevs7_Q-uwgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_aire_labels.shape)\n",
        "print(test_aire_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mRklxK5s388r"
      },
      "source": [
        "### Normalizar los datos.\n",
        "\n",
        "Hay que normalizar el conjunto de datos de prueba puesto que los datos tienen diferentes rangos como se puede observar en la tabla de estadisticas generales. Se van a utilizar diferentes tipos de normalización para hacer experimentos y analizar cual devuelve mejores resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlC5ooJrgjQF",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#datos del aire\n",
        "scaler = Normalizer().fit(train_aire_dataset)\n",
        "normed_train_aire_data = pd.DataFrame(scaler.transform(train_aire_dataset),columns=train_aire_dataset.columns)\n",
        "scaler = Normalizer().fit(train_aire_dataset)\n",
        "normed_test_aire_data = pd.DataFrame(scaler.transform(test_aire_dataset),columns=test_aire_dataset.columns)\n",
        "\n",
        "#datos del clima\n",
        "scaler = Normalizer().fit(train_clima_dataset)\n",
        "normed_train_clima_data = pd.DataFrame(scaler.transform(train_clima_dataset),columns=train_clima_dataset.columns)\n",
        "scaler = Normalizer().fit(train_clima_dataset)\n",
        "normed_test_clima_data = pd.DataFrame(scaler.transform(test_clima_dataset),columns=test_clima_dataset.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SmjdzxKzEu1-"
      },
      "source": [
        "## El modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVauw54CoITc",
        "colab_type": "text"
      },
      "source": [
        "### Guardar y restaurar los modelos\n",
        "Los diferentes modelos probados se van a  guardar utilizando las librerias proporcionadas por Tensorflow. El codigo a continuacion importa las librerias necesarias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-6prT3yo2OV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install h5py pyyaml\n",
        "#!pip install tf_nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPVLBj7oz18m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-60v8ODg0DbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls '/content/gdrive/My Drive/Colab Notebooks/Tesis/Modelos'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6SWtkIjhrZwa"
      },
      "source": [
        "### Construir el modelo\n",
        "\n",
        "Aquí, usaremos un modelo `Secuencial 'con dos capas ocultas conectadas densamente y una capa de salida que devuelve un valor único y continuo. Los pasos de construcción del modelo están envueltos en una función, `build_model`, para crear varios modelos que luego van a ser utilizados en el ensamblaje."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c26juK7ZG8j-",
        "colab": {}
      },
      "source": [
        "#[len(train_dataset.keys())]\n",
        "def build_model(dim):\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(16, activation=tf.nn.relu, input_shape=dim),\n",
        "    layers.Dense(16, activation=tf.nn.relu),\n",
        "    layers.Dense(1, activation=tf.nn.elu)\n",
        "  ])\n",
        "  \n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "  \n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cGbPb-PHGbhs",
        "colab": {}
      },
      "source": [
        "model_aire = build_model([len(train_aire_dataset.keys())])\n",
        "model_clima = build_model([len(train_clima_dataset.keys())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmR8OvUWyiQx",
        "colab_type": "text"
      },
      "source": [
        "* Se configura la parada  temprana para evitar el sobreajuste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuyMW_iPyhZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MLNsHugf7lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combinedInput = tf.keras.layers.concatenate([model_aire.output, model_clima.output])\n",
        " \n",
        "\n",
        "x = layers.Dense(4, activation=\"relu\")(combinedInput)\n",
        "x = layers.Dense(1, activation=\"linear\")(x)\n",
        " \n",
        "# our final model will accept categorical/numerical data on the MLP\n",
        "# input and images on the CNN input, outputting a single value (the\n",
        "# predicted price of the house)\n",
        "model = tf.keras.Model(inputs=[model_aire.input, model_clima.input], outputs=x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM6r6Kd1rADD",
        "colab_type": "text"
      },
      "source": [
        "La funcion plot_history se usara para mostrar los graficos del error al entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7jeB1rWq_St",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Abs Error [PM25]')\n",
        "  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,5])\n",
        "  plt.legend()\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error [$PM25^2$]')\n",
        "  plt.plot(hist['epoch'], hist['mean_squared_error'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Sj49Og4YGULr"
      },
      "source": [
        "### Inspeccionar el modelo\n",
        "\n",
        "Usando el método `.summary` se imprime la descripción simple del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ReAD0n6MsFK-",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Vt6W50qGsJAL"
      },
      "source": [
        "Compilar el modelo que usa las dos entradas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-d-gBaVtGTSC",
        "colab": {}
      },
      "source": [
        "#optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "#optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001, decay=0.999)\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(loss='mean_squared_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mean_absolute_error', 'mean_squared_error'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0-qWCsh6DlyH"
      },
      "source": [
        "### Entrena al modelo\n",
        "\n",
        "El modelo se va a entrenar durante 1000 épocas y registre la precisión de entrenamiento y validación en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sD7qHCmNIOY0",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"/content/gdrive/My Drive/Colab Notebooks/Tesis/Modelos/cpnormDataelu3.ckpt\"\n",
        "\n",
        "#Se pueden guardar checkpoints durante el entrenamiento.\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "\n",
        "# Display training progress by printing a single dot for each completed epoch\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit([normed_train_aire_data, normed_train_clima_data], train_aire_labels, \n",
        "                    validation_data=([normed_test_aire_data, normed_test_clima_data], test_aire_labels), \n",
        "                    epochs=EPOCHS,\n",
        "                    verbose=0, \n",
        "                    callbacks=[early_stop, PrintDot(), cp_callback])\n",
        "\n",
        "#Se pueden guardar el modelo completo\n",
        "model.save('/content/gdrive/My Drive/Colab Notebooks/Tesis/Modelos/normDataelu3.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU_QRvK3woPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tQm3pc0FYPQB"
      },
      "source": [
        "Visualice el progreso del entrenamiento del modelo utilizando las estadísticas almacenadas en el objeto `history`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4Xj91b-dymEy",
        "colab": {}
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3St8-DmrX8P4"
      },
      "source": [
        "El gráfico muestra que en el conjunto de validación, el error promedio es generalmente alrededor de +/- 1.8 para PM25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jl_yNr5n1kms",
        "colab": {}
      },
      "source": [
        "loss, mae, mse = model.evaluate([normed_test_aire_data, normed_test_clima_data], test_aire_labels, verbose=0)\n",
        "\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} PM25\".format(mae))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ft603OzXuEZC"
      },
      "source": [
        "### Hacer predicciones\n",
        "\n",
        "Finalmente, predice los valores de PM25 utilizando datos en el conjunto de pruebas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xe7RXH3N3CWU",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict([normed_test_aire_data, normed_test_clima_data]).flatten()\n",
        "\n",
        "plt.scatter(test_aire_labels, test_predictions)\n",
        "plt.xlabel('True Values [PM25]')\n",
        "plt.ylabel('Predictions [PM25]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OrkHGKZcusUo"
      },
      "source": [
        "Parece que nuestro modelo predice razonablemente bien. Echemos un vistazo a la distribución de errores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-OHX4DiXd8x",
        "colab": {}
      },
      "source": [
        "error = test_predictions - test_aire_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [PM25]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "r9_kI6MHu1UU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwcwWWV6sFxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import io\n",
        "url = \"http://www.mambiente.munimadrid.es/opendata/horario.csv\"\n",
        "\n",
        "urlData = requests.get(url).content\n",
        "datos_aire_horarios = pd.read_csv(io.StringIO(urlData.decode('utf-8')), sep=\";\")\n",
        "datos_aire_horarios.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKunHlzs3lFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open our new sheet and read some data.\n",
        "worksheet = c.open('contaminante_clave').sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "\n",
        "# Convert to a DataFrame and render.\n",
        "import pandas as pd\n",
        "columnas=['MAGNITUD', 'CONTAMINANTE']\n",
        "contaminante_clave = pd.DataFrame.from_records(rows, columns =columnas)\n",
        "contaminante_clave[columnas[0]] = contaminante_clave[columnas[0]].apply(pd.to_numeric) \n",
        "contaminante_clave.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xiqOofX1eXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "header_list = list(datos_aire_horarios)\n",
        "columns_name = header_list[1:8]\n",
        "columns_name.append(\"Valido\")\n",
        "columns_name.append(\"Hora\")\n",
        "columns_name.append(\"Valor\")\n",
        "\n",
        "datos_aire_horarios_pro= pd.DataFrame(columns=columns_name)\n",
        "\n",
        "for i in range(1,24):    \n",
        "    lista = header_list[1:8]\n",
        "    lista.append( \"V\" + (\"0\"+str(i))[-2:])\n",
        "    hora =\"H\" + (\"0\"+str(i))[-2:]\n",
        "    datos_aire_horarios1 = pd.melt(datos_aire_horarios, id_vars=lista, value_vars=hora )\n",
        "    datos_aire_horarios1.columns = columns_name    \n",
        "    datos_aire_horarios_pro = datos_aire_horarios_pro.append(datos_aire_horarios1)\n",
        "\n",
        "datos_aire_horarios_pro = datos_aire_horarios_pro[(datos_aire_horarios_pro.Valido =='V')]\n",
        "datos_aire_horarios_pro.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z-ofoC41_NL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datos_aire_horarios_pro = pd.merge(datos_aire_horarios_pro, contaminante_clave , left_on='MAGNITUD', right_on='MAGNITUD', copy=False)\n",
        "datos_aire_horarios_pro.drop(\"MAGNITUD\", axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiUIi19k499Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datos_aire_horarios_pro1 = pd.pivot_table(datos_aire_horarios_pro, columns='CONTAMINANTE', values=['Valor'], index=['Hora'], aggfunc=np.mean).reset_index()\n",
        "datos_aire_horarios_pro1\n",
        "\n",
        "list(datos_aire_horarios_pro1)\n",
        "\n",
        "flattened = pd.DataFrame(datos_aire_horarios_pro1.to_records(index=False))\n",
        "\n",
        "columnas= ['HORA', 'BEN',  'CH4',  'CO',  'EBE',\n",
        "                       'NMHC',  'NO',  'NO2',  'NOx',  'O3',\n",
        "                         'PM10',  'PM25',  'SO2',  'TCH',  'TOL'] \n",
        "\n",
        "flattened.columns = columnas\n",
        "\n",
        "flattened.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okXqzV9OBxBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_horario_dataset = flattened[columnas[1:15]].sample(frac=0.8,random_state=0)\n",
        "train_horario_labels = train_horario_dataset.pop('PM25')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5TxQmR6BJL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#datos del aire tiempo real\n",
        "scaler = Normalizer().fit(train_horario_dataset)\n",
        "normed_train_horario_data = pd.DataFrame(scaler.transform(train_horario_dataset),columns=train_horario_dataset.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMLOe032DIq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUX=datos_clima_diario[pd.DatetimeIndex(datos_clima_diario['FECHA']).month==5]\n",
        "AUX=AUX[1:19]\n",
        "AUX=AUX[columnas_clima[1:4]]\n",
        "\n",
        "scaler = Normalizer().fit(AUX)\n",
        "normed_train_horario_clima = pd.DataFrame(scaler.transform(AUX),columns=AUX.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAlQFHXKBH0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = model.predict([normed_train_horario_data, normed_train_horario_clima]).flatten()\n",
        "plt.scatter(train_horario_labels, test_predictions)\n",
        "plt.xlabel('True Values [PM25]')\n",
        "plt.ylabel('Predictions [PM25]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square')\n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqjVphKhXlCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = test_predictions - train_horario_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [PM25]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}